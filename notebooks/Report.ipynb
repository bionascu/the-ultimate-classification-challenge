{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme multi-class classification\n",
    "\n",
    "ID2223 Scalable Machine Learning and Deep Learning\n",
    "\n",
    "**Federico Baldassarre (fedbal@kth.se) and Beatrice Ionascu (bionascu@kth.se)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "# add the 'src' directory so we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from utils.paths import data_raw_dir\n",
    "from utils.paths import data_processed_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "The goal of this project is to classify products from [Cdiscount](https://www.cdiscount.com/), Franceâ€™s largest non-food e-commerce company, based on the product images on the company's website. Being able to correctly predict the category of products is important in ensuring that new products are well classified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data](../figures/data.png)\n",
    "\n",
    "The Cdiscount dataset consists of 15 million images at 180x180 resolution of almost 9\n",
    "million products. The training data consists of a list of 7,069,896 dictionaries, one per product. Each dictionary contains a product id, the category id of the product, and between\n",
    "1-4 images, stored in a list. In addition, each category id has a corresponding level1,\n",
    "level2, and level3 name, in French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_pickle(os.path.join(data_processed_dir, 'categories.pickle'))\n",
    "display(HTML(categories.filter(like='category', axis=1).head().to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_id_prod_distrib.pickle'))\n",
    "print('There are {} products.'.format(product_distrib.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_id_img_distrib.pickle'))\n",
    "print('There are {} images.'.format(image_distrib.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_counts = pd.read_csv(os.path.join(data_raw_dir, 'category_names.csv'))\n",
    "print(categ_counts.nunique().to_frame('Category counts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5270 available categories are very unevenly distributed amongst the products. As seen below, there are many categories with just a few products and few categories with very many products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_id_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_id_prod_distrib.pickle'))\n",
    "cat_1_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_1_prod_distrib.pickle'))\n",
    "cat_2_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_2_prod_distrib.pickle'))\n",
    "cat_3_distrib = pd.read_pickle(os.path.join(data_processed_dir, 'cat_3_prod_distrib.pickle'))\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16,10))\n",
    "ax=ax.ravel()\n",
    "cat_1_distrib.hist(log=True, bins=50,ax=ax[0])\n",
    "ax[0].set_title('Category Level 1 ({})'.format(cat_1_distrib.size)); ax[0].set_xlabel('Number of products')\n",
    "cat_2_distrib.hist(log=True, bins=50,ax=ax[1])\n",
    "ax[1].set_title('Category Level 2 ({})'.format(cat_2_distrib.size)); ax[1].set_xlabel('Number of products')\n",
    "cat_3_distrib.hist(log=True, bins=50,ax=ax[2])\n",
    "ax[2].set_title('Category Level 3 ({})'.format(cat_3_distrib.size)); ax[2].set_xlabel('Number of products')\n",
    "cat_id_distrib.hist(log=True, bins=50,ax=ax[3])\n",
    "ax[3].set_title('Category id ({})'.format(cat_id_distrib.size)); ax[3].set_xlabel('Number of products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories with the most and least products are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(categories.filter(like='category'), \n",
    "         cat_id_distrib.sort_values(ascending=False).iloc[np.r_[0:5, -5:0]].to_frame('counts'),\n",
    "         left_index=True, right_index=True).sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "Use xceptio as feature extraction\n",
    "Architecture: Learn a few conv layer and a softmax dense\n",
    "compare negative sampling with regular cross entropy loss\n",
    "\n",
    "## Pre-processing\n",
    "### Label encoding\n",
    "\n",
    "## Feature Extraction\n",
    "### TfRecords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation graph\n",
    "![computation graph](../figures/computational_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- We trained the network using two different loss functions.\n",
    "- explain training and testing split\n",
    "- explain epoch / step/batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results\n",
    "\n",
    "\n",
    "![results](../figures/metrics_v2.png)\n",
    "\n",
    "- classification accuracy and loss per image\n",
    "- can't test on the test data since we don't have access to it ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Future work\n",
    "\n",
    "- group images into products -- report results per product\n",
    "- test the influence of the negative sample size in sampled softmax\n",
    "- use heirarchy\n",
    "- use OCR for books\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
